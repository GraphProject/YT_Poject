{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9229ba90",
   "metadata": {},
   "source": [
    "# YouTube Keyword Generation\n",
    "    \n",
    "    1 -  Film & Animation\n",
    "    2 - Autos & Vehicles\n",
    "    10 - Music\n",
    "    15 - Pets & Animals\n",
    "    17 - Sports\n",
    "    18 - Short Movies\n",
    "    19 - Travel & Events\n",
    "    20 - Gaming\n",
    "    21 - Videoblogging\n",
    "    22 - People & Blogs\n",
    "    23 - Comedy\n",
    "    24 - Entertainment\n",
    "    25 - News & Politics\n",
    "    26 - Howto & Style\n",
    "    27 - Education\n",
    "    28 - Science & Technology\n",
    "    29 - Nonprofits & Activism\n",
    "    30 - Movies\n",
    "    31 - Anime/Animation\n",
    "    32 - Action/Adventure\n",
    "    33 - Classics\n",
    "    34 - Comedy\n",
    "    35 - Documentary\n",
    "    36 - Drama\n",
    "    37 - Family\n",
    "    38 - Foreign\n",
    "    39 - Horror\n",
    "    40 - Sci-Fi/Fantasy\n",
    "    41 - Thriller\n",
    "    42 - Shorts\n",
    "    43 - Shows\n",
    "    44 - Trailers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef4f5b",
   "metadata": {},
   "source": [
    "# Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from operator import itemgetter\n",
    "from networkx.algorithms import community\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d0d15",
   "metadata": {},
   "source": [
    "# Data load from scraped CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72df048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"YT/IN_youtube_trending_data.csv\")\n",
    "keyword_list = []\n",
    "for i in range(0,50):\n",
    "    print('Loop No:'+ str(i))\n",
    "    #string = df.loc[i, 'tags']+df.loc[i, 'description']+df.loc[i, 'title']\n",
    "    string = df.loc[i, 'tags']\n",
    "    #print('String::',string)\n",
    "    keywords_all = keywords(string, words=30, lemmatize=True).split('\\n')\n",
    "    #print('Keyword::'+ str(keywords_all))\n",
    "    #print(type(keywords_all))\n",
    "    \n",
    "    for keyword in keywords_all:\n",
    "        print('Video_ID :'+str(df.loc[i, 'video_id'])+'::Keyword::'+str(keyword)+'\\n')\n",
    "    \n",
    "    keyword_list.append(keywords_all)\n",
    "    #keywords_all = keywords(text).split('\\n')\n",
    "    \n",
    "    \n",
    "    #print(keywords_all[4])\n",
    "    \"\"\"\n",
    "    for keywords in keywords_all:\n",
    "        print(keywords)\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a50b487",
   "metadata": {},
   "source": [
    "# Videowise Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93872780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "keyword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d472c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "count = 0\n",
    "for keyword in keyword_list:\n",
    "    print(count,end='')\n",
    "    print(keyword)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e06db",
   "metadata": {},
   "source": [
    "# Marge all keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9f623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "keyword_marge = []\n",
    "for keyword in keyword_list:\n",
    "    keyword_marge = keyword_marge + keyword\n",
    "keyword_marge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3845868",
   "metadata": {},
   "source": [
    "# Generate list of unique keywords from marge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c837b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "#Keyword_Marge_To_Keyword_Set \n",
    "#Findout the Unique keyword\n",
    "Keyword_marge_Set = set(keyword_marge)\n",
    "print(Keyword_marge_Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d3c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "#Create Unique_Keyword_List\n",
    "Keyword_marge_list = list(Keyword_marge_Set)\n",
    "print(Keyword_marge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f2d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "for i in range (0,len(Keyword_marge_list)):\n",
    "    if (Keyword_marge_list[i] == ''):\n",
    "        Keyword_marge_list[i] = 'NAN'\n",
    "    print(Keyword_marge_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f179cd",
   "metadata": {},
   "source": [
    "# Matrix Generation of Common Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a752ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "## Corrected \n",
    "\n",
    "arr = np.zeros((len(keyword_list),len(Keyword_marge_list)), dtype=int)\n",
    "print(arr)\n",
    "count = 0\n",
    "for keyword in keyword_list:\n",
    "    \n",
    "    print(\"List i: \", len(keyword))\n",
    "    \n",
    "    for i in range (0,len(keyword)):\n",
    "        \n",
    "        for j in range (0,len(Keyword_marge_list)):\n",
    "            \n",
    "            print(\"Count \"+str(count)+\" i \"+str(i)+\" j \"+str(j))\n",
    "            print(Keyword_marge_list[j], keyword[i])\n",
    "            print('Count::',count)\n",
    "            \n",
    "            if (Keyword_marge_list[j] == keyword[i]):\n",
    "                print(\"Matched Count \"+str(count)+\" i \"+str(i)+\" j \"+str(j))\n",
    "                print('Matched',keyword[i], Keyword_marge_list[j])\n",
    "                arr[count][j]=1\n",
    "                print(arr)\n",
    "                break  \n",
    "                \n",
    "                    \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            if (keyword__all_list[j] != ''):\n",
    "                if (keyword[i] == keyword__all_list[j]):\n",
    "                    print('Matched',i,j)\n",
    "                    print('Matched',keyword[i], keyword__all_list[j])\n",
    "                    arr[count][j]=1\n",
    "            \"\"\"\n",
    "            \n",
    "    count = count + 1\n",
    "    print(count)\n",
    "    print(arr)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f48eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a34c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "#Print Array \n",
    "count = 0\n",
    "for keyword in keyword_list:\n",
    "    for i in range (0,len(Keyword_marge_list)):\n",
    "        #print(count,j,end = ' ')\n",
    "        print(arr[count][i],end = ' ')\n",
    "    print('\\n')\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a393aa",
   "metadata": {},
   "source": [
    "# Graph Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d08a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8994d1b",
   "metadata": {},
   "source": [
    "# * Connection matrix among YT videos based on common keywords\n",
    "# * Connect the YT videos with an edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59244b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN\n",
    "#Print Array \n",
    "edge_list = []\n",
    "count = 0\n",
    "for keyword in keyword_list:\n",
    "    #count_col = 0\n",
    "    for i in range (0,len(Keyword_marge_list)):\n",
    "        print (count, i)\n",
    "        if(arr[count][i]==1):\n",
    "            for j in range (count+1,len(keyword_list)):\n",
    "                \n",
    "                print (j,i,end=' ')\n",
    "                \n",
    "                print(arr[j][i],end = ' ')\n",
    "                if (arr[j][i] == 1):\n",
    "                    print('-----------------------------')\n",
    "                    print(Keyword_marge_list[i])\n",
    "                    \n",
    "                    G.add_edge(count,j,edge_labels=Keyword_marge_list[i])\n",
    "                    print('One',end=' ')\n",
    "                    \n",
    "                \n",
    "                \n",
    "            print('\\n')\n",
    "            \n",
    "\n",
    "    \n",
    "    print('\\n')\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b89f2",
   "metadata": {},
   "source": [
    "# Information avout Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c89f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(G))\n",
    "print(\"V : \",G.nodes)\n",
    "print(\"E : \",G.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2cf47",
   "metadata": {},
   "source": [
    "# Degree Centrality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d940dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_dict = nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "G.density = {}\n",
    "for i in degree_dict:\n",
    "    G.density[i] = (degree_dict[i])*1000\n",
    "    G.density[i] = math.ceil(G.density[i])\n",
    "    \n",
    "G.density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b494ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color = [float(G.degree(v)) for v in G]\n",
    "node_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb5749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, \n",
    "        node_size = [G.density[v] for v in G],\n",
    "        with_labels=True,\n",
    "        node_color = node_color)\n",
    "\n",
    "#plt.figure(figsize=(10,5))\n",
    "plt.savefig(\"DegreeCentrality.png\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b8a092",
   "metadata": {},
   "source": [
    "# Closeness Centrality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_dict = nx.closeness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c2c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "G.density = {}\n",
    "for i in closeness_dict:\n",
    "    G.density[i] = (closeness_dict[i])*1000\n",
    "    G.density[i] = math.ceil(G.density[i])\n",
    "    \n",
    "G.density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e03272",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color = [float(G.degree(v)) for v in G]\n",
    "node_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cde6fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nx.draw(G, \n",
    "        node_size = [G.density[v] for v in G],\n",
    "        with_labels=True,\n",
    "        node_color = node_color)\n",
    "\n",
    "#plt.figure(figsize=(10,5))\n",
    "plt.savefig(\"ClosenessCentrality.png\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b0041c",
   "metadata": {},
   "source": [
    "# Betweenness Centrality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_dict = nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50469699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "G.density = {}\n",
    "for i in betweenness_dict:\n",
    "    G.density[i] = (betweenness_dict[i])*10000\n",
    "    G.density[i] = math.ceil(G.density[i])\n",
    "    \n",
    "G.density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89bc651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node_color = [float(G.degree(v)) for v in G]\n",
    "node_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, \n",
    "        node_size = [G.density[v] for v in G],\n",
    "        with_labels=True,\n",
    "        node_color = node_color)\n",
    "\n",
    "#plt.figure(figsize=(10,5))\n",
    "plt.savefig(\"BeteenessCentrality.png\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc6a46",
   "metadata": {},
   "source": [
    "# EigenVector Centrality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvector_dict = nx.eigenvector_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc285b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "G.density = {}\n",
    "for i in eigenvector_dict:\n",
    "    G.density[i] = (eigenvector_dict[i])*2000\n",
    "    G.density[i] = math.ceil(G.density[i])\n",
    "    \n",
    "G.density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color = [float(G.degree(v)) for v in G]\n",
    "node_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, \n",
    "        node_size = [G.density[v] for v in G],\n",
    "        with_labels=True,\n",
    "        node_color = node_color)\n",
    "\n",
    "#plt.figure(figsize=(10,5))\n",
    "plt.savefig(\"EigenVector.png\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b86532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
